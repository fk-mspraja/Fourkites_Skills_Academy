# API Mappings for Ocean Debugging Skill
# Based on: Support Team Tools Catalog (SUPPORT-SKILLS-AND-TOOLS-CATALOG.md)
# Maps investigation steps to specific API calls, queries, and data sources

version: "1.0.0"
skill_id: "ocean_debugging"

# ============================================
# API SOURCES
# ============================================

sources:

  # --------------------------------------------
  # FourKites Platform / Tracking API
  # --------------------------------------------
  tracking_api:
    name: "Tracking API"
    type: "rest_api"
    base_url: "${TRACKING_API_URL}"
    auth:
      type: "api_key"
      header: "X-API-Key"
      credential: "env:TRACKING_API_KEY"
    timeout: 30000
    retry:
      max_attempts: 3
      backoff: "exponential"

    operations:

      get_load_details:
        method: "GET"
        path: "/v1/loads/{load_id}"
        params:
          load_id:
            type: "path"
            required: true
        response_schema:
          type: "object"
          properties:
            exists: boolean
            id: string
            status: string
            mode: string
            carrier:
              id: string
              name: string
            shipper:
              id: string
              name: string
            tracking:
              method: string
              source: string  # RPA, API, EDI, Vessel
              subscription_id: string
            milestones:
              type: array
              items:
                code: string
                timestamp: datetime
                location: string
        cache_ttl: 300

      get_load_timeline:
        method: "GET"
        path: "/v1/loads/{load_id}/timeline"
        params:
          load_id:
            type: "path"
            required: true
          include_all_events:
            type: "query"
            default: true

  # --------------------------------------------
  # Super API (Internal)
  # --------------------------------------------
  super_api:
    name: "Super API"
    type: "rest_api"
    base_url: "${SUPER_API_URL}"
    auth:
      type: "api_key"
      header: "X-Super-Key"
      credential: "env:SUPER_API_KEY"
    timeout: 30000

    operations:

      get_tracking_config:
        method: "GET"
        path: "/v1/tracking/config/{load_id}"
        params:
          load_id:
            type: "path"
            required: true
        response_schema:
          type: "object"
          properties:
            tracking_id: string
            primary_identifier: string  # booking_number, bill_of_lading, container
            identifier_value: string
            subscription_id: string
            tracking_source: string  # RPA, API, EDI
        cache_ttl: 600

      get_subscription_details:
        method: "GET"
        path: "/v1/subscriptions/{subscription_id}"
        params:
          subscription_id:
            type: "path"
            required: true

  # --------------------------------------------
  # Just Transform (JT) API
  # --------------------------------------------
  justtransform_api:
    name: "Just Transform API"
    type: "rest_api"
    base_url: "${JT_API_URL}"
    auth:
      type: "basic"
      credentials:
        username: "env:JT_USERNAME"
        password: "env:JT_PASSWORD"
    timeout: 60000  # JT can be slow
    note: "Same credentials as JT Portal UI (shared credentials)"

    operations:

      get_subscription_history:
        method: "GET"
        path: "/api/v1/ocean/subscriptions/{subscription_id}/history"
        params:
          subscription_id:
            type: "path"
            required: true
          from_date:
            type: "query"
            format: "YYYY-MM-DD"
          to_date:
            type: "query"
            format: "YYYY-MM-DD"
        response_schema:
          type: "object"
          properties:
            subscription_id: string
            history:
              type: array
              items:
                event_id: string
                timestamp: datetime
                event_code: string  # VD, AG, ET
                crawled_output: object  # Raw from carrier portal
                response: object  # Formatted for FourKites
                status: string
        pagination:
          type: "offset"
          default_limit: 100

      get_event_details:
        method: "GET"
        path: "/api/v1/ocean/events/{event_id}"
        params:
          event_id:
            type: "path"
            required: true
        response_includes:
          - "crawled_output"  # Raw scraped data
          - "formatted_response"  # What was sent to FourKites
          - "carrier_portal_screenshot"  # If available

  # --------------------------------------------
  # Data Hub API (Ocean Checklist Tool)
  # --------------------------------------------
  data_hub_api:
    name: "Data Hub API"
    type: "rest_api"
    base_url: "${DATA_HUB_URL}"
    auth:
      type: "bearer"
      credential: "env:DATA_HUB_TOKEN"
    status: "production"
    note: "Already used by support team - basic troubleshooting data"

    operations:

      get_ocean_checklist:
        method: "GET"
        path: "/v1/ocean/{load_id}/checklist"
        params:
          load_id:
            type: "path"
            required: true
        response_schema:
          type: "object"
          properties:
            load_exists: boolean
            tracking_active: boolean
            subscription_valid: boolean
            recent_updates: array
            basic_diagnostics: object

  # --------------------------------------------
  # SigNoz (ClickHouse Logs)
  # --------------------------------------------
  signoz_clickhouse:
    name: "SigNoz Logs"
    type: "clickhouse"
    host: "${SIGNOZ_CLICKHOUSE_HOST}"
    port: 9000
    database: "signoz_logs"
    auth:
      type: "basic"
      credentials:
        username: "env:SIGNOZ_USER"
        password: "env:SIGNOZ_PASSWORD"
    timeout: 120000  # Queries can be slow
    note: "Primary investigation tool - 15-20 min of manual work"

    tables:
      - name: "distributed_logs"
        purpose: "Service logs"
        retention: "30 days"
        key_columns:
          - "service_name"
          - "body"
          - "timestamp"
          - "trace_id"
          - "span_id"
          - "severity_text"
          - "environment"

    query_templates:

      ocean_processing_logs:
        description: "Get PROCESS_OCEAN_UPDATE logs for a container/booking"
        template: |
          SELECT
            body,
            timestamp,
            trace_id,
            span_id,
            severity_text,
            JSONExtractString(body, 'event_code') as event_code,
            JSONExtractString(body, 'container_number') as container_number,
            JSONExtractString(body, 'correlation_id') as correlation_id,
            JSONExtractString(body, 'data_source') as data_source,
            JSONExtractString(body, 'vessel_name') as vessel_name
          FROM signoz_logs.distributed_logs
          WHERE service_name = 'multimodel_carrier_updates_worker'
            AND body LIKE '%PROCESS_OCEAN_UPDATE%'
            AND (
              body LIKE '%{container_number}%'
              OR body LIKE '%{booking_number}%'
            )
            AND environment = 'production'
            AND timestamp >= now() - INTERVAL {days_back} DAY
          ORDER BY timestamp DESC
          LIMIT {limit}
        params:
          container_number:
            required: false
          booking_number:
            required: false
          days_back:
            default: 30
            note: "Ocean shipments can take weeks - need 30 days"
          limit:
            default: 1000

      service_logs_by_trace:
        description: "Get all logs for a specific trace ID"
        template: |
          SELECT *
          FROM signoz_logs.distributed_logs
          WHERE trace_id = '{trace_id}'
          ORDER BY timestamp ASC

  # --------------------------------------------
  # Redshift Data Warehouse
  # --------------------------------------------
  redshift:
    name: "Redshift DWH"
    type: "redshift"
    host: "${REDSHIFT_HOST}"
    port: 5439
    database: "dwh"
    auth:
      type: "aws_iam"
      role: "${REDSHIFT_IAM_ROLE}"

    tables:

      company_relationships:
        description: "THE MOST CRITICAL TABLE - carrier-shipper relationships"
        note: "#1 cause of Awaiting Tracking Info when missing"
        columns:
          - relationship_id
          - shipper_id
          - carrier_id
          - status
          - is_active
          - created_date
          - updated_date

      fact_carrier_file_logs:
        description: "Carrier file processing logs (CFW -> GWEX -> LW)"
        columns:
          - file_id
          - carrier_id
          - file_type
          - received_at
          - processed_at
          - status
          - error_message

      fact_carrier_record_logs:
        description: "Individual record processing from carrier files"
        columns:
          - record_id
          - file_id
          - load_id
          - status
          - match_type

      load_validation_data_mart:
        description: "Conventional load creation records"
        note: "Does NOT include Booking API created loads"

      tracking_update_v3s:
        description: "All tracking updates received"

    query_templates:

      check_network_relationship:
        description: "Check if carrier-shipper relationship exists and is active"
        template: |
          SELECT
            relationship_id,
            status,
            is_active,
            created_date
          FROM company_relationships
          WHERE shipper_id = '{shipper_id}'
            AND carrier_id = '{carrier_id}'
        params:
          shipper_id:
            required: true
          carrier_id:
            required: true

      check_carrier_files:
        description: "Check if carrier is sending files"
        template: |
          SELECT
            file_id,
            file_type,
            received_at,
            status,
            record_count
          FROM fact_carrier_file_logs
          WHERE carrier_id = '{carrier_id}'
            AND received_at >= '{from_date}'
          ORDER BY received_at DESC
          LIMIT 100

      find_similar_stuck_loads:
        description: "Find other loads from same carrier stuck in same state"
        template: |
          SELECT COUNT(*) as affected_loads
          FROM fact_loads
          WHERE carrier_id = '{carrier_id}'
            AND status = 'AWAITING_TRACKING_INFO'
            AND created_date >= now() - INTERVAL '{days}' DAY

  # --------------------------------------------
  # AWS S3 (File Storage)
  # --------------------------------------------
  s3:
    name: "AWS S3"
    type: "s3"
    region: "${AWS_REGION}"
    auth:
      type: "aws_cli"
      profile: "${AWS_PROFILE}"

    buckets:

      edi_files:
        name: "${EDI_BUCKET}"
        prefix_patterns:
          ea315: "edi/ea315/{carrier_id}/{date}/"
          e214: "edi/214/{carrier_id}/{date}/"
        operations:
          list_files:
            description: "List EDI files for a carrier"
          download_file:
            description: "Download specific EDI file for parsing"

      carrier_super_files:
        name: "${SUPER_FILES_BUCKET}"
        prefix_patterns:
          super: "carrier_files/{carrier_id}/"

# ============================================
# STEP-TO-API MAPPINGS
# ============================================

step_mappings:

  step_1_platform_check:
    primary:
      source: "tracking_api"
      operation: "get_load_details"
    fallback:
      source: "data_hub_api"
      operation: "get_ocean_checklist"

  step_2_get_tracking_config:
    primary:
      source: "super_api"
      operation: "get_tracking_config"

  step_3_check_justtransform:
    primary:
      source: "justtransform_api"
      operation: "get_subscription_history"
    detail:
      source: "justtransform_api"
      operation: "get_event_details"

  step_4_signoz_logs:
    primary:
      source: "signoz_clickhouse"
      query: "ocean_processing_logs"
    correlation:
      source: "signoz_clickhouse"
      query: "service_logs_by_trace"

  check_network_relationship:
    source: "redshift"
    query: "check_network_relationship"
    critical: true

  check_carrier_files:
    source: "redshift"
    query: "check_carrier_files"

# ============================================
# RESPONSE PARSERS
# ============================================

parsers:

  signoz_log_parser:
    description: "Parse raw JSON logs from SigNoz into structured data"
    note: "Based on Surya's HTML Log Analyzer tool"
    input: "raw_log_body"
    output:
      type: "object"
      fields:
        - name: "event_code"
          path: "$.event_code"
          type: "string"
          enum: ["VD", "AG", "ET", "AD", "OA", "DL"]
        - name: "event_time"
          path: "$.event_time"
          type: "datetime"
        - name: "container_number"
          path: "$.container_number"
          type: "string"
        - name: "correlation_id"
          path: "$.correlation_id"
          type: "string"
        - name: "data_source"
          path: "$.source"
          type: "string"
          enum: ["JT", "EDI", "API", "VESSEL"]
        - name: "vessel_name"
          path: "$.vessel.name"
          type: "string"
        - name: "location"
          path: "$.location"
          type: "object"
          fields:
            - city_state
            - country
            - latitude
            - longitude
    aggregations:
      - name: "total_records"
        type: "count"
      - name: "unique_et_updates"
        type: "count_distinct"
        field: "event_time"
        filter: "event_code == 'ET'"
      - name: "unique_locations"
        type: "count_distinct"
        field: "location.city_state"

  jt_event_parser:
    description: "Parse JT event comparing crawled vs formatted"
    input: "jt_event"
    output:
      type: "object"
      fields:
        - name: "event_code"
        - name: "crawled_timestamp"
          path: "$.crawled_output.event_time"
        - name: "formatted_timestamp"
          path: "$.response.event_time"
        - name: "data_match"
          computed: "crawled_timestamp == formatted_timestamp"

# ============================================
# CACHING STRATEGY
# ============================================

caching:
  default_ttl: 300  # 5 minutes

  by_source:
    tracking_api: 300
    super_api: 600
    justtransform_api: 60  # JT data changes frequently
    signoz_clickhouse: 60
    redshift: 3600  # Slow-changing data

  invalidation:
    on_new_update: true
    on_status_change: true

# ============================================
# ERROR HANDLING
# ============================================

error_handling:

  retry_strategy:
    max_attempts: 3
    backoff: "exponential"
    base_delay_ms: 1000

  fallback_behavior:
    tracking_api:
      fallback_to: "data_hub_api"
    justtransform_api:
      fallback_to: null
      human_handoff: true
      message: "JT API unavailable - please check JT Portal manually"

  timeout_handling:
    signoz_clickhouse:
      timeout_ms: 120000
      on_timeout: "partial_results"
      message: "Query took too long - showing partial results"
